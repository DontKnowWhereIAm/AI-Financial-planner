#!/usr/bin/env python3
r"""
categorize_statement_onecall.py

Reads a bank statement (PDF/CSV/XLS/XLSX), extracts transactions, then sends ALL
transaction descriptions in ONE OpenAI API call to classify them into categories.

Output CSV columns:
  Month, Date, Description, Amount, Category, Confidence, NormalizedDescription

Usage:
  python categorize_statement_onecall.py "C:\path\to\statement.xlsx"
  python categorize_statement_onecall.py stmt.csv --assume-positive-expenses
  python categorize_statement_onecall.py stmt.pdf --all

Requires:
  pip install pandas python-dateutil pdfplumber openpyxl openai
Env:
  OPENAI_API_KEY must be set.
"""

from __future__ import annotations
import argparse, os, sys, re, json
from pathlib import Path
from typing import List, Optional, Dict, Any
import pandas as pd
from dateutil import parser as dateparser
from openai import OpenAI

# -------- Categories (your set) --------
CATEGORIES = [
    "Housing","Food","Transportation","Education","Books",
    "Subscriptions","Entertainment","Healthcare","Insurance",
    "Savings","Other"
]

# -------- Column heuristics --------
DATE_CANDIDATES = [
    "date","post date","posting date","transaction date","trans date",
    "posted date","value date","statement date"
]
DESC_CANDIDATES = [
    "description","details","detail","memo","narrative","payee","merchant","transaction"
]
AMOUNT_CANDIDATES = ["amount","amt","transaction amount","value","amount ($)","amount usd"]
DEBIT_CANDIDATES  = ["debit","withdrawal","withdrawals","charges","spend","expense","debits"]
CREDIT_CANDIDATES = ["credit","deposit","deposits","payments","credits","income"]

# -------- Helpers --------
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [re.sub(r"\s+", " ", str(c)).strip().lower() for c in df.columns]
    return df

def find_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    cols = list(df.columns)
    for c in candidates:
        if c in cols:
            return c
    for c in candidates:
        for col in cols:
            if c in col:
                return col
    return None

def coerce_amount(x) -> Optional[float]:
    if pd.isna(x): return None
    s = str(x).strip()
    if s == "": return None
    neg = s.startswith("(") and s.endswith(")")
    if neg:
        s = s[1:-1]
    s = re.sub(r"[^0-9.\-]", "", s)
    if s.count("-") > 1:
        s = s.replace("-", "")
        s = "-" + s
    try:
        val = float(s)
        return -abs(val) if neg else val
    except ValueError:
        return None

def coerce_date(x) -> Optional[pd.Timestamp]:
    if pd.isna(x): return None
    # Let pandas handle datetimes/Excel serials first
    dt = pd.to_datetime(x, errors="coerce")
    if pd.notna(dt):
        return dt
    s = str(x).strip()
    if not s: return None
    try:
        return pd.to_datetime(dateparser.parse(s, dayfirst=False, yearfirst=False))
    except Exception:
        return None

def build_signed_amount(df: pd.DataFrame, amount_col: Optional[str], debit_col: Optional[str], credit_col: Optional[str]) -> pd.Series:
    if amount_col:
        return df[amount_col].map(coerce_amount)
    debit = df[debit_col].map(coerce_amount) if debit_col else None
    credit = df[credit_col].map(coerce_amount) if credit_col else None
    if debit is not None and credit is not None:
        return (credit.fillna(0) - debit.fillna(0))
    if debit is not None:
        return -debit
    if credit is not None:
        return credit
    raise ValueError("No amount/debit/credit column detected.")

def read_csv_or_excel(path: Path) -> pd.DataFrame:
    if path.suffix.lower() == ".csv":
        df = pd.read_csv(path)
    else:
        df = pd.read_excel(path)
    return normalize_columns(df)

def read_pdf_tables(path: Path) -> pd.DataFrame:
    try:
        import pdfplumber
    except Exception:
        raise RuntimeError("pdfplumber not installed. Run: pip install pdfplumber")
    rows = []
    with pdfplumber.open(path) as pdf:
        for page in pdf.pages:
            try:
                tables = page.extract_tables()
            except Exception:
                tables = []
            for tbl in tables or []:
                if not tbl or len(tbl) < 2: continue
                header = [re.sub(r"\s+", " ", (cell or "")).strip().lower() for cell in tbl[0]]
                for r in tbl[1:]:
                    if any(c is not None and str(c).strip() for c in r):
                        rows.append(dict(zip(header, r)))
    if not rows:
        raise ValueError("No tabular data found in PDF. Try exporting CSV/XLSX from your bank.")
    return normalize_columns(pd.DataFrame(rows))

def load_transactions(path: Path) -> pd.DataFrame:
    ext = path.suffix.lower()
    if ext in [".csv", ".xls", ".xlsx"]:
        df = read_csv_or_excel(path)
    elif ext == ".pdf":
        df = read_pdf_tables(path)
    else:
        raise ValueError("Unsupported file type. Use PDF, CSV, or Excel.")
    date_col   = find_col(df, DATE_CANDIDATES)
    desc_col   = find_col(df, DESC_CANDIDATES)
    amount_col = find_col(df, AMOUNT_CANDIDATES)
    debit_col  = find_col(df, DEBIT_CANDIDATES)
    credit_col = find_col(df, CREDIT_CANDIDATES)

    missing = []
    if not date_col: missing.append("date")
    if not desc_col: missing.append("description")
    if not (amount_col or debit_col or credit_col): missing.append("amount/debit/credit")
    if missing:
        raise ValueError(f"Column detection failed: {', '.join(missing)}\nFound: {list(df.columns)}")

    out = pd.DataFrame()
    out["Date"] = df[date_col].map(coerce_date)
    out["Description"] = df[desc_col].astype(str).str.replace(r"\s+", " ", regex=True).str.strip()
    out["Amount"] = build_signed_amount(df, amount_col, debit_col, credit_col)
    out = out.dropna(subset=["Date","Amount"])
    return out

def select_expenses(trans: pd.DataFrame, assume: Optional[str]) -> pd.DataFrame:
    t = trans.copy()
    if assume == "negative":
        expenses = t[t["Amount"] < 0]
    elif assume == "positive":
        expenses = t[t["Amount"] > 0].copy()
        expenses["Amount"] = -expenses["Amount"].abs()
    else:
        if (t["Amount"] < 0).any():
            expenses = t[t["Amount"] < 0]
        else:
            expenses = t[t["Amount"] > 0].copy()
            if not expenses.empty:
                expenses["Amount"] = -expenses["Amount"].abs()
    return expenses

def add_month_and_sort(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["Month"] = df["Date"].dt.to_period("M").astype(str)
    return df.sort_values(["Month","Date","Description"])

# -------- One-call classification --------

# JSON schema for array output (aligned to input order)
RESPONSE_SCHEMA = {
    "name": "transaction_classifications",
    "schema": {
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "category": {"type": "string", "enum": CATEGORIES},
                "confidence": {"type": "number", "minimum": 0, "maximum": 1},
                "normalized_description": {"type": "string"}
            },
            "required": ["category", "confidence", "normalized_description"],
            "additionalProperties": False
        }
    },
    "strict": True
}

SYSTEM_PROMPT = (
    "You are a precise personal finance classifier for student spending. "
    "Given a list of bank transaction descriptions, you must return a JSON object "
    "with one key 'items' whose value is an array of the SAME LENGTH and ORDER as the input. "
    "Each element must contain:\n"
    " - category: one of [Housing, Food, Transportation, Education, Books, Subscriptions, "
    "   Entertainment, Healthcare, Insurance, Savings, Other]\n"
    " - confidence: number 0..1\n"
    " - normalized_description: canonical merchant/brand name\n\n"
    "Guidance:\n"
    "- Housing: rent, dorm fees, utilities bundled with housing.\n"
    "- Food: groceries, cafes, restaurants, meal plans, delivery.\n"
    "- Transportation: public transit, ride share, gas, parking.\n"
    "- Education: tuition, course fees, lab fees.\n"
    "- Books: textbooks & course materials (campus bookstore ok).\n"
    "- Subscriptions: recurring software/streaming/memberships.\n"
    "- Entertainment: movies, events, gaming, leisure.\n"
    "- Healthcare: pharmacy, clinics, medical expenses.\n"
    "- Insurance: health, auto, renter's.\n"
    "- Savings: transfers to savings/investments; ambiguous bank-to-bank transfers -> Savings.\n"
    "- Other: anything that doesn't fit above.\n"
    "Return ONLY valid JSON. Do not include explanations."
)


import json
from openai import OpenAI
client = OpenAI()

def classify_all_in_one_call(descriptions: list[str], model: str) -> list[dict]:
    """
    Sends ALL descriptions in one Chat Completions call.
    Expects JSON: {"items":[{category, confidence, normalized_description}, ...]} length == len(descriptions)
    Returns a Python list of dicts aligned 1:1 with input descriptions.
    """
    user_payload = {"descriptions": descriptions}  # keep order, keep duplicates

    resp = client.chat.completions.create(
        model=model,                      # e.g. "gpt-4o" or "gpt-4o-mini"
        temperature=0.1,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": (
                "Classify these descriptions. Reply ONLY with JSON object "
                "like {\"items\": [...]} and keep array length and order identical.\n\n"
                + json.dumps(user_payload, ensure_ascii=False)
            )},
        ],
    )

    content = resp.choices[0].message.content
    data = json.loads(content)              # should be {"items":[...]}
    items = data.get("items", [])
    if not isinstance(items, list):
        raise ValueError("Model did not return an 'items' array.")
    if len(items) != len(descriptions):
        raise ValueError(f"Length mismatch: got {len(items)} items for {len(descriptions)} descriptions.")

    allowed = {
        "Housing","Food","Transportation","Education","Books",
        "Subscriptions","Entertainment","Healthcare","Insurance","Savings","Other"
    }
    cleaned = []
    for i, it in enumerate(items):
        cat = it.get("category", "Other")
        if cat not in allowed:
            cat = "Other"
        try:
            conf = float(it.get("confidence", 0.0))
        except Exception:
            conf = 0.0
        norm = it.get("normalized_description") or descriptions[i]
        cleaned.append({
            "category": cat,
            "confidence": conf,
            "normalized_description": norm
        })
    return cleaned

# -------- Main --------

def main():
    ap = argparse.ArgumentParser(description="Categorize transactions via ONE OpenAI API call.")
    ap.add_argument("input", help="Path to statement (PDF/CSV/XLS/XLSX)")
    ap.add_argument("--out", help="Output CSV (default: <stem>_categorized.csv)")
    ap.add_argument("--all", action="store_true", help="Categorize ALL rows (not just expenses).")
    ap.add_argument("--assume-positive-expenses", action="store_true", help="Force positives as expenses.")
    ap.add_argument("--assume-negative-expenses", action="store_true", help="Force negatives as expenses (default if negatives exist).")
    ap.add_argument("--model", default="gpt-4o-mini", help="OpenAI model to use (e.g., gpt-4o, gpt-4o-mini).")
    args = ap.parse_args()

    if not os.getenv("OPENAI_API_KEY"):
        print("ERROR: Set OPENAI_API_KEY before running.", file=sys.stderr)
        sys.exit(2)

    in_path = Path(args.input.strip('"').strip("'"))
    if not in_path.exists():
        print(f"File not found: {in_path}", file=sys.stderr)
        sys.exit(1)

    # Load & choose transactions
    trans = load_transactions(in_path)
    assume = "positive" if args.assume_positive_expenses else ("negative" if args.assume_negative_expenses else None)
    rows = trans if args.all else select_expenses(trans, assume=assume)

    if rows.empty:
        print("No rows to categorize (try --all or adjust assumptions).", file=sys.stderr)
        # still write empty output for consistency
        out_path = Path(args.out) if args.out else in_path.with_name(in_path.stem + "_categorized.csv")
        pd.DataFrame(columns=["Month","Date","Description","Amount","Category","Confidence","NormalizedDescription"]).to_csv(out_path, index=False)
        print(f"Wrote 0 rows to: {out_path.resolve()}")
        sys.exit(0)

    rows = add_month_and_sort(rows)
    rows["Amount"] = rows["Amount"].astype(float)

    # Prepare descriptions in one list (include duplicates, preserve order)
    descriptions = list(rows["Description"].astype(str))

    # --- ONE CALL to classify all descriptions ---
    try:
        results = classify_all_in_one_call(descriptions, args.model)
    except Exception as e:
        print("Classification error:", e, file=sys.stderr)
        sys.exit(3)

    # Apply results back by position
    cats = pd.DataFrame(results)
    assert len(cats) == len(rows), "Length mismatch after classification."
    out_df = rows.reset_index(drop=True).copy()
    out_df["Category"] = cats["category"].values
    out_df["Confidence"] = cats["confidence"].astype(float).values
    out_df["NormalizedDescription"] = cats["normalized_description"].values

    # Select columns & save
    out_df = out_df[["Month","Date","Description","Amount","Category","Confidence","NormalizedDescription"]]
    out_path = Path(args.out) if args.out else in_path.with_name(in_path.stem + "_categorized.csv")
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_df.to_csv(out_path, index=False)

    print(f"Wrote {len(out_df)} rows to: {out_path.resolve()}")
    print("Columns:", ", ".join(out_df.columns))

if __name__ == "__main__":
    main()
